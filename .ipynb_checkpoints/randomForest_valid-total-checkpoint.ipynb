{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cql/anaconda2/lib/python2.7/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "/Users/cql/anaconda2/lib/python2.7/site-packages/sklearn/grid_search.py:42: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "from pandas import concat\n",
    "import matplotlib.pyplot as plt\n",
    "import xgboost as xgb\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from sklearn.cross_validation import cross_val_score # K折交叉验证模块\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn import preprocessing\n",
    "from sklearn import svm\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from imblearn.over_sampling import SMOTE, ADASYN\n",
    "from sklearn import svm\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.multiclass import OutputCodeClassifier\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import f_regression\n",
    "from sklearn.feature_selection import f_classif\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from imblearn.pipeline import Pipeline as ImPineline\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.grid_search import RandomizedSearchCV\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "import time\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def submit(fileName, testTotal, preds):\n",
    "    submission = testTotal[['id']]\n",
    "    submission['pred'] = preds\n",
    "    submission.to_csv('./predicts/'+fileName, header=False, index=False)\n",
    "    return submission\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractFeature(train_feature, partition=2, randomPartion=False, prefix=\"p\", onlyAvg=False, filterLow=False, levelFeature=False, scaleSpec=True, smooth=False):\n",
    "    if scaleSpec:\n",
    "        train_feature = pd.DataFrame(scale(train_feature, axis=1))\n",
    "    if smooth:\n",
    "        train_feature = train_feature.rolling(100, axis=1).mean()\n",
    "    if filterLow:\n",
    "        train_feature[train_feature<1] = 0\n",
    "    plen = train_feature.shape[1]/partition\n",
    "    features = pd.DataFrame()\n",
    "    avgs = pd.DataFrame()\n",
    "    for i in range(0, partition):\n",
    "        pstart = random.randint(0, train_feature.shape[1]-plen-1)\n",
    "        pendExclue = pstart + plen + 1\n",
    "        avgC = train_feature.iloc[:, pstart:pendExclue].mean(axis=1)\n",
    "        stdC = train_feature.iloc[:, pstart:pendExclue].std(axis=1)\n",
    "        maxC = train_feature.iloc[:, pstart:pendExclue].max(axis=1)\n",
    "        minC = train_feature.iloc[:, pstart:pendExclue].min(axis=1)\n",
    "        medianC = train_feature.iloc[:, pstart:pendExclue].median(axis=1)\n",
    "        diffC = train_feature.iloc[:, pstart:pendExclue].diff(axis=1).iloc[:,1:]\n",
    "        features[prefix+'_avg'+str(i)] = avgC\n",
    "        avgs[prefix+'_avg'+str(i)] = avgC\n",
    "        if onlyAvg==False:\n",
    "            features[prefix+'_std'+str(i)] = stdC\n",
    "            features[prefix+'_median'+str(i)] = medianC\n",
    "            features[prefix+'_max'+str(i)] = maxC\n",
    "            features[prefix+'_min'+str(i)] = minC\n",
    "            features[prefix+'_avg_m_std'+str(i)] = stdC/avgC\n",
    "            features[prefix+'_max_m_avg'+str(i)] = maxC/avgC\n",
    "            features[prefix+'_min_m_avg'+str(i)] = minC/avgC\n",
    "#             features[prefix+'_media_m_avg'+str(i)] = medianC/avgC\n",
    "    if levelFeature:\n",
    "        level_feature = extractFeature(avgs, prefix=\"l\", partition = 4)\n",
    "        features = pd.concat([features, level_feature], axis = 1)\n",
    "    return features.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readTotalFeature(fileName, maxFileIndex, hasLabel=True, partition = 20):\n",
    "    total_train_feature = pd.DataFrame()\n",
    "    for i in range(0, maxFileIndex+1):\n",
    "        print('processing:' + str(i))\n",
    "        train_set = pd.read_csv(fileName + str(i) +'.csv', header=None)\n",
    "        renameCol = {0:'id'}\n",
    "        if hasLabel:\n",
    "            renameCol[train_set.shape[1]-1] = 'label'\n",
    "        train_set.rename(columns=renameCol, inplace=True)\n",
    "        if hasLabel:\n",
    "            processed_train = extractFeature(train_set.iloc[:,1:-1],partition, levelFeature=False, smooth=False)\n",
    "            processed_train['label'] = train_set.label\n",
    "        else:\n",
    "            processed_train = extractFeature(train_set.iloc[:,1:],partition, levelFeature=False, smooth=False)\n",
    "            processed_train['id'] = train_set.id\n",
    "        total_train_feature = total_train_feature.append(processed_train, ignore_index=True)\n",
    "    return total_train_feature.sample(total_train_feature.shape[0], replace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "validMode = False\n",
    "reFeature = True\n",
    "rng = np.random.RandomState(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cql/anaconda2/lib/python2.7/site-packages/sklearn/preprocessing/data.py:164: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\"Numerical issues were encountered \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing:1\n",
      "processing:2\n",
      "processing:3\n",
      "processing:4\n",
      "processing:5\n",
      "processing:6\n",
      "processing:7\n",
      "processing:8\n",
      "processing:9\n",
      "processing:10\n",
      "processing:11\n",
      "processing:12\n",
      "processing:13\n",
      "processing:14\n",
      "processing:15\n",
      "processing:16\n",
      "processing:17\n",
      "processing:18\n",
      "processing:19\n",
      "processing:20\n",
      "processing:21\n",
      "processing:22\n",
      "processing:23\n",
      "processing:24\n",
      "processing:25\n",
      "processing:26\n",
      "processing:27\n",
      "processing:28\n",
      "processing:29\n",
      "processing:30\n",
      "processing:31\n",
      "processing:32\n",
      "processing:33\n",
      "processing:34\n",
      "processing:35\n",
      "processing:36\n",
      "processing:37\n",
      "processing:38\n",
      "processing:39\n",
      "processing:40\n",
      "processing:41\n",
      "processing:42\n",
      "processing:43\n",
      "processing:44\n",
      "processing:45\n",
      "processing:46\n",
      "processing:47\n",
      "processing:48\n"
     ]
    }
   ],
   "source": [
    "if reFeature:\n",
    "    total_train_feature = readTotalFeature('./train_feature_all_', 48, partition=20)\n",
    "    total_train_feature.to_csv('./train_feature_check_point.csv', index=False)\n",
    "else :\n",
    "    total_train_feature = pd.read_csv('./train_feature_check_point.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>p_avg0</th>\n",
       "      <th>p_std0</th>\n",
       "      <th>p_median0</th>\n",
       "      <th>p_max0</th>\n",
       "      <th>p_min0</th>\n",
       "      <th>p_avg_m_std0</th>\n",
       "      <th>p_max_m_avg0</th>\n",
       "      <th>p_min_m_avg0</th>\n",
       "      <th>p_avg1</th>\n",
       "      <th>p_std1</th>\n",
       "      <th>...</th>\n",
       "      <th>p_min_m_avg18</th>\n",
       "      <th>p_avg19</th>\n",
       "      <th>p_std19</th>\n",
       "      <th>p_median19</th>\n",
       "      <th>p_max19</th>\n",
       "      <th>p_min19</th>\n",
       "      <th>p_avg_m_std19</th>\n",
       "      <th>p_max_m_avg19</th>\n",
       "      <th>p_min_m_avg19</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>277707</th>\n",
       "      <td>-0.554383</td>\n",
       "      <td>0.059356</td>\n",
       "      <td>-0.561780</td>\n",
       "      <td>-0.432753</td>\n",
       "      <td>-0.649321</td>\n",
       "      <td>-0.107066</td>\n",
       "      <td>0.780602</td>\n",
       "      <td>1.171249</td>\n",
       "      <td>-1.479519</td>\n",
       "      <td>0.040049</td>\n",
       "      <td>...</td>\n",
       "      <td>1.156425</td>\n",
       "      <td>0.119969</td>\n",
       "      <td>0.072373</td>\n",
       "      <td>0.127305</td>\n",
       "      <td>0.279832</td>\n",
       "      <td>-0.098060</td>\n",
       "      <td>0.603262</td>\n",
       "      <td>2.332535</td>\n",
       "      <td>-0.817376</td>\n",
       "      <td>star</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165111</th>\n",
       "      <td>0.130094</td>\n",
       "      <td>0.156567</td>\n",
       "      <td>0.097690</td>\n",
       "      <td>0.808683</td>\n",
       "      <td>-0.242007</td>\n",
       "      <td>1.203487</td>\n",
       "      <td>6.216123</td>\n",
       "      <td>-1.860242</td>\n",
       "      <td>1.215479</td>\n",
       "      <td>0.355265</td>\n",
       "      <td>...</td>\n",
       "      <td>1.452407</td>\n",
       "      <td>0.345879</td>\n",
       "      <td>0.169136</td>\n",
       "      <td>0.337425</td>\n",
       "      <td>0.721318</td>\n",
       "      <td>-0.108698</td>\n",
       "      <td>0.489004</td>\n",
       "      <td>2.085462</td>\n",
       "      <td>-0.314265</td>\n",
       "      <td>star</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>466998</th>\n",
       "      <td>0.889223</td>\n",
       "      <td>0.193668</td>\n",
       "      <td>0.918894</td>\n",
       "      <td>1.146085</td>\n",
       "      <td>-0.109112</td>\n",
       "      <td>0.217795</td>\n",
       "      <td>1.288861</td>\n",
       "      <td>-0.122705</td>\n",
       "      <td>0.761597</td>\n",
       "      <td>0.530123</td>\n",
       "      <td>...</td>\n",
       "      <td>2.000628</td>\n",
       "      <td>0.413291</td>\n",
       "      <td>0.266640</td>\n",
       "      <td>0.467421</td>\n",
       "      <td>0.661528</td>\n",
       "      <td>-1.403538</td>\n",
       "      <td>0.645163</td>\n",
       "      <td>1.600633</td>\n",
       "      <td>-3.396002</td>\n",
       "      <td>star</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89267</th>\n",
       "      <td>-0.111437</td>\n",
       "      <td>0.603689</td>\n",
       "      <td>0.024682</td>\n",
       "      <td>1.164571</td>\n",
       "      <td>-1.990702</td>\n",
       "      <td>-5.417317</td>\n",
       "      <td>-10.450488</td>\n",
       "      <td>17.863926</td>\n",
       "      <td>0.220863</td>\n",
       "      <td>0.165643</td>\n",
       "      <td>...</td>\n",
       "      <td>5.359980</td>\n",
       "      <td>0.680863</td>\n",
       "      <td>0.144474</td>\n",
       "      <td>0.685468</td>\n",
       "      <td>1.085446</td>\n",
       "      <td>0.356073</td>\n",
       "      <td>0.212192</td>\n",
       "      <td>1.594220</td>\n",
       "      <td>0.522973</td>\n",
       "      <td>star</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196749</th>\n",
       "      <td>-0.450888</td>\n",
       "      <td>0.732692</td>\n",
       "      <td>-0.417082</td>\n",
       "      <td>2.081867</td>\n",
       "      <td>-4.960900</td>\n",
       "      <td>-1.624997</td>\n",
       "      <td>-4.617256</td>\n",
       "      <td>11.002498</td>\n",
       "      <td>-0.381772</td>\n",
       "      <td>0.598910</td>\n",
       "      <td>...</td>\n",
       "      <td>8.001517</td>\n",
       "      <td>-0.303786</td>\n",
       "      <td>0.328695</td>\n",
       "      <td>-0.258716</td>\n",
       "      <td>0.857559</td>\n",
       "      <td>-1.839937</td>\n",
       "      <td>-1.081995</td>\n",
       "      <td>-2.822905</td>\n",
       "      <td>6.056686</td>\n",
       "      <td>galaxy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 161 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          p_avg0    p_std0  p_median0    p_max0    p_min0  p_avg_m_std0  \\\n",
       "277707 -0.554383  0.059356  -0.561780 -0.432753 -0.649321     -0.107066   \n",
       "165111  0.130094  0.156567   0.097690  0.808683 -0.242007      1.203487   \n",
       "466998  0.889223  0.193668   0.918894  1.146085 -0.109112      0.217795   \n",
       "89267  -0.111437  0.603689   0.024682  1.164571 -1.990702     -5.417317   \n",
       "196749 -0.450888  0.732692  -0.417082  2.081867 -4.960900     -1.624997   \n",
       "\n",
       "        p_max_m_avg0  p_min_m_avg0    p_avg1    p_std1   ...    p_min_m_avg18  \\\n",
       "277707      0.780602      1.171249 -1.479519  0.040049   ...         1.156425   \n",
       "165111      6.216123     -1.860242  1.215479  0.355265   ...         1.452407   \n",
       "466998      1.288861     -0.122705  0.761597  0.530123   ...         2.000628   \n",
       "89267     -10.450488     17.863926  0.220863  0.165643   ...         5.359980   \n",
       "196749     -4.617256     11.002498 -0.381772  0.598910   ...         8.001517   \n",
       "\n",
       "         p_avg19   p_std19  p_median19   p_max19   p_min19  p_avg_m_std19  \\\n",
       "277707  0.119969  0.072373    0.127305  0.279832 -0.098060       0.603262   \n",
       "165111  0.345879  0.169136    0.337425  0.721318 -0.108698       0.489004   \n",
       "466998  0.413291  0.266640    0.467421  0.661528 -1.403538       0.645163   \n",
       "89267   0.680863  0.144474    0.685468  1.085446  0.356073       0.212192   \n",
       "196749 -0.303786  0.328695   -0.258716  0.857559 -1.839937      -1.081995   \n",
       "\n",
       "        p_max_m_avg19  p_min_m_avg19   label  \n",
       "277707       2.332535      -0.817376    star  \n",
       "165111       2.085462      -0.314265    star  \n",
       "466998       1.600633      -3.396002    star  \n",
       "89267        1.594220       0.522973    star  \n",
       "196749      -2.822905       6.056686  galaxy  \n",
       "\n",
       "[5 rows x 161 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(483851, 161)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "display(total_train_feature.head())\n",
    "total_train_feature.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(338695, 160)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = total_train_feature.iloc[:,:-1]\n",
    "Y = total_train_feature.iloc[:,-1]\n",
    "\n",
    "# Split the dataset in two equal parts\n",
    "x, t_x, y, t_y = train_test_split(\n",
    "    X, Y, test_size=0.3, random_state=0)\n",
    "x.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def outlier_rejection(X, y):\n",
    "    model = IsolationForest(n_jobs=-1, random_state=rng)\n",
    "    model.fit(X)\n",
    "    y_pred = model.predict(X)\n",
    "    return X[y_pred == 1], y[y_pred == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "smote = SMOTE()\n",
    "anova_filter = SelectKBest(f_classif, k=(int)(x.shape[1]*0.3))\n",
    "model = RandomForestClassifier(n_jobs=4, n_estimators= class_weight='balanced', max_depth=70,  verbose=1,random_state=rng)\n",
    "# model = AdaBoostClassifier(random_state=rng)\n",
    "# model = GradientBoostingClassifier(random_state=rng,verbose=1)\n",
    "# model = XGBClassifier()\n",
    "# model = KNeighborsClassifier(n_neighbors = 3, n_jobs=-1)\n",
    "scaler = StandardScaler()\n",
    "clf = ImPineline([\n",
    "#     ('anova', anova_filter),\n",
    "#     ('scaler',scaler),\n",
    "    ('smote',smote),\n",
    "    ('model', model)\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "if validMode:\n",
    "    rs = clf.fit(x, y)\n",
    "    preds_test = clf.predict(t_x)\n",
    "    clf.score(t_x, t_y)\n",
    "    print(\"%0.3f\" % f1_score(t_y, preds_test, average='macro'))  \n",
    "    print(classification_report(t_y, preds_test, labels=['galaxy', 'qso', 'star', 'unknown']))\n",
    "    print(confusion_matrix(t_y, preds_test, labels=['galaxy', 'qso', 'star', 'unknown']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "if validMode:\n",
    "    clf = RandomForestClassifier(n_jobs=-1, class_weight='balanced',  verbose=1 )\n",
    "    rs = clf.fit(x, y)\n",
    "    preds_test = clf.predict(t_x)\n",
    "    # clf.score(t_x, t_y)\n",
    "    print('f1: %.2f' % f1_score(t_y, preds_test, average='macro')) \n",
    "    print(classification_report(t_y, preds_test, labels=['galaxy', 'qso', 'star', 'unknown']))\n",
    "    print(confusion_matrix(t_y, preds_test, labels=['galaxy', 'qso', 'star', 'unknown']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "if validMode:\n",
    "    rs = clf.fit(x, y)\n",
    "    scores = cross_val_score(clf, x, y, cv=3, n_jobs=-1, verbose=1, scoring='f1_macro')\n",
    "    print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
    "#     preds_test = clf.predict(t_x)\n",
    "    # clf.score(t_x, t_y)\n",
    "#     print(\"%0.3f\" % f1_score(t_y, preds_test, average='macro'))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "if validMode:\n",
    "    importances = model.feature_importances_\n",
    "    std = np.std([tree.feature_importances_ for tree in model.estimators_],\n",
    "                 axis=0)\n",
    "    indices = np.argsort(importances)[::-1]\n",
    "\n",
    "    # Print the feature ranking\n",
    "    print(\"Feature ranking:\")\n",
    "\n",
    "    for f in range(X.shape[1]):\n",
    "        print(\"%d. feature %d (%f)\" % (f + 1, indices[f], importances[indices[f]]))\n",
    "\n",
    "    # Plot the feature importances of the forest\n",
    "    plt.figure()\n",
    "    plt.title(\"Feature importances\")\n",
    "    plt.bar(range(X.shape[1]), importances[indices],\n",
    "           color=\"r\", yerr=std[indices], align=\"center\")\n",
    "    plt.xticks(range(X.shape[1]), indices)\n",
    "    plt.xlim([-1, X.shape[1]])\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "if validMode:\n",
    "    smote = SMOTE()\n",
    "    parameters = {\n",
    "        'max_depth':[60, 70, 80],  #70\n",
    "        'max_features':[0.5,0.6,0.7], #0.6\n",
    "    #     'min_samples_split':[2, 4, 8, 20], #2\n",
    "    #     'min_samples_leaf':[1,4,8,20], #1\n",
    "    #     'min_weight_fraction_leaf':[0,0.05,0.1,0.2], #0\n",
    "        'max_leaf_nodes':[800, 1000, 1200], #1000\n",
    "    #      'bootstrap':[True, False], #False\n",
    "    #     'oob_score':[True, False], #False\n",
    "    #     'class_weight':[None,'balanced'], #balanced\n",
    "        'n_estimators':[10, 20], #10\n",
    "    #     'criterion':['gini','entropy']\n",
    "    }\n",
    "    clf = GridSearchCV(RandomForestClassifier(n_jobs=4, max_depth=20), parameters, cv=5,\n",
    "                           scoring='f1_macro', n_jobs=8, verbose=2)\n",
    "    clf.fit(x, y)\n",
    "    print(clf.best_params_)\n",
    "    means = clf.cv_results_['mean_test_score']\n",
    "    stds = clf.cv_results_['std_test_score']\n",
    "    for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "        print(\"%0.3f (+/-%0.03f) for %r\" % (mean, std * 2, params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing:0\n",
      "processing:1\n",
      "processing:2\n",
      "processing:3\n",
      "processing:4\n",
      "processing:5\n",
      "processing:6\n",
      "processing:7\n",
      "processing:8\n",
      "processing:9\n"
     ]
    }
   ],
   "source": [
    "if reFeature:\n",
    "    testTotal = readTotalFeature('./test_feature_all_', 9, partition=20)\n",
    "    testTotal.to_csv('./test_feature_checkpoint.csv', index=False)\n",
    "    testTotal.head()\n",
    "else :\n",
    "    testTotal = pd.read_csv('./test_feature_checkpoint.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(483851, 161)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testTotal.head()\n",
    "total_train_feature.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.fit(total_train_feature.iloc[:,:-1], total_train_feature.iloc[:,-1])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x = testTotal.iloc[:,:-1]\n",
    "pred = clf.predict(test_x)\n",
    "timestr = time.strftime(\"%m%d_%H%M\")\n",
    "submit(timestr+'_rf_ew_20.csv',testTotal, pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_train_feature.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_train_feature[:,:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
