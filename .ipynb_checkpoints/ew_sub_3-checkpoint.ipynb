{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "from pandas import concat\n",
    "import matplotlib.pyplot as plt\n",
    "import xgboost as xgb\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from sklearn.cross_validation import cross_val_score # K折交叉验证模块\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn import preprocessing\n",
    "from sklearn import svm\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from imblearn.over_sampling import SMOTE, ADASYN\n",
    "from sklearn import svm\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.multiclass import OutputCodeClassifier\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import f_regression\n",
    "from sklearn.feature_selection import f_classif\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from imblearn.pipeline import Pipeline as ImPineline\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.grid_search import RandomizedSearchCV\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from scipy.signal import lfilter\n",
    "import pywt\n",
    "\n",
    "import time\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spec = total_train_feature.iloc[:,:-1].head()\n",
    "\n",
    "def specLineNum(spec, windowSize=2, threshold=0.8):\n",
    "    fs = pd.Series()\n",
    "    ss = pd.Series()\n",
    "    for i in range(windowSize, spec.shape[1]):\n",
    "        s = spec.iloc[:,i-windowSize]\n",
    "        e = spec.iloc[:,i]\n",
    "        isFs = (e>threshold) & ((e-s)>threshold)\n",
    "        isSS = (e<threshold) & ((e-s)<-threshold)\n",
    "        if(fs.size==0):\n",
    "            fs = isFs.astype(int)\n",
    "        else:\n",
    "            fs = fs + isFs.astype(int)\n",
    "        if(ss.size==0):\n",
    "            ss = isSS.astype(int)\n",
    "        else:\n",
    "            ss = ss + isSS.astype(int)\n",
    "    combine = pd.concat([fs, ss], axis=1)\n",
    "    combine.columns = ['fs','ss']\n",
    "    return combine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def waveletFilter(x, wavelet=\"db4\", level=1, mode=\"hard\", scaleNum=0.5):\n",
    "    coeff = pywt.wavedec( x, wavelet, mode=\"per\", axis=1 )\n",
    "    uthresh = scaleNum * np.sqrt( 2*np.log( x.shape[1] ) )\n",
    "    coeff[1:] = ( pywt.threshold( i, value=uthresh, mode=mode ) for i in coeff[1:] )\n",
    "    coeff\n",
    "    # # reconstruct the signal using the thresholded coefficients\n",
    "    y = pywt.waverec( coeff, wavelet, mode=\"per\" )\n",
    "    y = pd.DataFrame(y)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def qsoFeature(data, doScale=True):\n",
    "    if doScale:\n",
    "        data = pd.DataFrame(scale(data, axis=1))\n",
    "    std1 = data.iloc[:,850:880].std(axis=1)\n",
    "    std2 = data.iloc[:,885:898].std(axis=1)\n",
    "    std3 = data.iloc[:,900:1000].std(axis=1)\n",
    "    f1 = (std1<0.3) & (std2>0.35) & (std3<0.35)\n",
    "    f3 = (std2*std2)/(std1*std3+0.1)\n",
    "    d1 = std1+0.2\n",
    "    f2 = (std2>d1)\n",
    "    qsof = pd.concat([f1, f2, f3], axis=1)\n",
    "    qsof.columns = ['qso_f1','qso_f2','qso_f3']\n",
    "    return (qsof)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def staticFeature(data, doScale=False):\n",
    "    if doScale:\n",
    "        data = pd.DataFrame(scale(data, axis=1))\n",
    "    mean =data.mean(axis=1)\n",
    "    std =data.std(axis=1)\n",
    "    d_max =data.max(axis=1)\n",
    "    d_min =data.min(axis=1)\n",
    "    d_25 =data.quantile(0.25, axis=1)\n",
    "    d_50 =data.quantile(0.5, axis=1)\n",
    "    d_75 =data.quantile(0.75, axis=1)\n",
    "    return pd.concat([mean, std, d_max, d_min, d_25, d_50, d_75], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def intervalEWFeature(d, start=0, end=-1, filterThrehold=1):\n",
    "    cp = d\n",
    "#     cp[abs(cp)<filterThrehold] = 0\n",
    "    rd = cp.iloc[:, start:end]\n",
    "    specLines = specLineNum(rd[abs(rd)>filterThrehold])\n",
    "    ew_absorb = rd[(rd<0)&(abs(rd)>filterThrehold)].sum(axis=1)\n",
    "    ew_fs = rd[(rd>0)&(abs(rd)>filterThrehold)].sum(axis=1)\n",
    "    rd_mean = rd.mean(axis=1)+0.1\n",
    "#     st_feature = staticFeature(d)\n",
    "#     diff_feature = extractFeature(cp.diff(axis=1).iloc[:,1:], 3, levelFeature=False, smooth=False)\n",
    "\n",
    "    return pd.concat([ew_absorb, ew_fs, specLines], axis=1)\n",
    "\n",
    "def smooth(filterSet):\n",
    "    n = 5  # the larger n is, the smoother curve will be\n",
    "    b = [1.0 / n] * n\n",
    "    a = 1\n",
    "    filterSet = lfilter(b, a, filterSet, axis=1)\n",
    "    return pd.DataFrame(filterSet)\n",
    "\n",
    "def EWByRangeList(d, rangeList, filterThrehold=1, isSmooth=False, doScale=True):\n",
    "    if doScale:\n",
    "        d = pd.DataFrame(scale(d, axis=1))\n",
    "    if isSmooth:\n",
    "        d=smooth(d)\n",
    "    ewfAll = pd.DataFrame()\n",
    "    for r in rangeList:\n",
    "        start, end = r\n",
    "        ewf = intervalEWFeature(d, start, end, filterThrehold)\n",
    "        newNames = ['ew_' + str(start) + '_' + str(end) + '_' + str(v) for v in ewf.columns.values]\n",
    "        ewf.columns = newNames\n",
    "        ewfAll = pd.concat([ewfAll,ewf], axis=1)\n",
    "    return ewfAll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def submit(fileName, testTotal, preds):\n",
    "    submission = testTotal[['id']]\n",
    "    submission['pred'] = preds\n",
    "    submission.to_csv('./predicts/'+fileName, header=False, index=False)\n",
    "    return submission\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractFeature(train_feature, partition=2, randomPartion=False, prefix=\"p\", onlyAvg=False, filterLow=False, levelFeature=False, scaleSpec=False, smooth=False):\n",
    "    if scaleSpec:\n",
    "        train_feature = pd.DataFrame(scale(train_feature, axis=1))\n",
    "    if smooth:\n",
    "        train_feature = train_feature.rolling(100, axis=1).mean()\n",
    "    if filterLow:\n",
    "        train_feature[train_feature<1] = 0\n",
    "    plen = train_feature.shape[1]/partition\n",
    "    features = pd.DataFrame()\n",
    "    avgs = pd.DataFrame()\n",
    "    for i in range(0, partition):\n",
    "        pstart = random.randint(0, train_feature.shape[1]-plen-1)\n",
    "        pendExclue = pstart + plen + 1\n",
    "        avgC = train_feature.iloc[:, pstart:pendExclue].mean(axis=1)\n",
    "        stdC = train_feature.iloc[:, pstart:pendExclue].std(axis=1)\n",
    "        maxC = train_feature.iloc[:, pstart:pendExclue].max(axis=1)\n",
    "        minC = train_feature.iloc[:, pstart:pendExclue].min(axis=1)\n",
    "        medianC = train_feature.iloc[:, pstart:pendExclue].median(axis=1)\n",
    "        diffC = train_feature.iloc[:, pstart:pendExclue].diff(axis=1).iloc[:,1:]\n",
    "        features[prefix+'_avg'+str(i)] = avgC\n",
    "        avgs[prefix+'_avg'+str(i)] = avgC\n",
    "        if onlyAvg==False:\n",
    "            features[prefix+'_std'+str(i)] = stdC\n",
    "            features[prefix+'_median'+str(i)] = medianC\n",
    "            features[prefix+'_max'+str(i)] = maxC\n",
    "            features[prefix+'_min'+str(i)] = minC\n",
    "            features[prefix+'_avg_m_std'+str(i)] = stdC/avgC\n",
    "            features[prefix+'_max_m_avg'+str(i)] = maxC/avgC\n",
    "            features[prefix+'_min_m_avg'+str(i)] = minC/avgC\n",
    "            features[prefix+'_media_m_avg'+str(i)] = medianC/avgC\n",
    "    if levelFeature:\n",
    "        level_feature = extractFeature(avgs, prefix=\"l\", partition = 4)\n",
    "        features = pd.concat([features, level_feature], axis = 1)\n",
    "    return features.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readTotalFeature(fileName, maxFileIndex, hasLabel=True, partition = 20, ewFeature=True, addQsoFeature=True, doWavlet=False,diffFeature=True, addFFt=True):\n",
    "    total_train_feature = pd.DataFrame()\n",
    "    for i in range(0, maxFileIndex+1):\n",
    "        print('processing:' + str(i))\n",
    "        train_set = pd.read_csv(fileName + str(i) +'.csv', header=None)\n",
    "        renameCol = {0:'id'}\n",
    "        if hasLabel:\n",
    "            renameCol[train_set.shape[1]-1] = 'label'\n",
    "        train_set.rename(columns=renameCol, inplace=True)\n",
    "        if hasLabel:\n",
    "            processed_train = pd.DataFrame()\n",
    "            rawFeature = train_set.iloc[:,1:-1]\n",
    "        else:\n",
    "            rawFeature = train_set.iloc[:,1:]\n",
    "        if doWavlet:\n",
    "            rawFeature = waveletFilter(rawFeature, scaleNum=1)\n",
    "        processed_train = extractFeature(rawFeature, partition, levelFeature=False, smooth=False)\n",
    "        if ewFeature:\n",
    "            rangeList = [(0,20),(30,100),(1040,1060),(1380,1394),(2344,2360),(2360,2380),(2420,2440),(0,300), (0, 500), (500, 1000),(850, 1000), (1000, 1300),(1500,2000), (1500, 2600), (2500, 2600)]\n",
    "            ew_feature = EWByRangeList(rawFeature, rangeList, filterThrehold=0.5, doScale=True)\n",
    "            processed_train = pd.concat([processed_train, ew_feature], axis=1)\n",
    "        if addQsoFeature:\n",
    "            qso_feature = qsoFeature(rawFeature)\n",
    "            processed_train = pd.concat([processed_train, qso_feature], axis=1)\n",
    "        if addFFt:\n",
    "            ff =abs(pd.DataFrame(np.fft.fft(rawFeature, axis=1))).iloc[:, :(rawFeature.shape[1]/2)]\n",
    "            fftfeature = extractFeature(ff, 20, levelFeature=False, smooth=False, scaleSpec=True)\n",
    "            processed_train = pd.concat([processed_train, fftfeature], axis=1)\n",
    "        st_feature = staticFeature(rawFeature)            \n",
    "        processed_train = pd.concat([processed_train, st_feature], axis=1)\n",
    "        if hasLabel:\n",
    "            processed_train['label'] = train_set.label\n",
    "        else:\n",
    "            processed_train['id'] = train_set.id\n",
    "        total_train_feature = total_train_feature.append(processed_train, ignore_index=True)\n",
    "    return total_train_feature.sample(total_train_feature.shape[0], replace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "validMode = True\n",
    "reFeature = True\n",
    "partition = 30\n",
    "rng = np.random.RandomState(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing:0\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "global name 'd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mNameError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-74-7040965a2f34>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mreFeature\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mtotal_train_feature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreadTotalFeature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./train_feature_all_'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpartition\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpartition\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mtotal_train_feature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./train_feature_check_point.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mtotal_train_feature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./train_feature_check_point.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-72-962a1d7b6954>\u001b[0m in \u001b[0;36mreadTotalFeature\u001b[0;34m(fileName, maxFileIndex, hasLabel, partition, ewFeature, addQsoFeature, doWavlet, diffFeature, addFFt)\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0mfftfeature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextractFeature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mff\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevelFeature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msmooth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscaleSpec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m             \u001b[0mprocessed_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mprocessed_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfftfeature\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0mst_feature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstaticFeature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m         \u001b[0mprocessed_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mprocessed_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mst_feature\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasLabel\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: global name 'd' is not defined"
     ]
    }
   ],
   "source": [
    "if reFeature:\n",
    "    total_train_feature = readTotalFeature('./train_feature_all_', 1, partition=partition)\n",
    "    total_train_feature.to_csv('./train_feature_check_point.csv', index=False)\n",
    "else :\n",
    "    total_train_feature = pd.read_csv('./train_feature_check_point.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_train_feature = total_train_feature.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_train_feature.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# total_train_feature.iloc[:,1:-1].diff(axis=1).iloc[:,1:].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_train_feature[total_train_feature.label=='unknown'].head(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = total_train_feature.iloc[:,:-1]\n",
    "Y = total_train_feature.iloc[:,-1]\n",
    "\n",
    "# Split the dataset in two equal parts\n",
    "x, t_x, y, t_y = train_test_split(\n",
    "    X, Y, test_size=0.3, random_state=0)\n",
    "x.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smote = SMOTE()\n",
    "anova_filter = SelectKBest(f_classif, k=(int)(x.shape[1]*0.9))\n",
    "model = RandomForestClassifier(n_jobs=8, class_weight='balanced', max_depth=20,   verbose=1,random_state=rng)\n",
    "# model = AdaBoostClassifier(random_state=rng)\n",
    "# model = GradientBoostingClassifier(random_state=rng,verbose=1)\n",
    "# model = XGBClassifier()\n",
    "# model = KNeighborsClassifier(n_neighbors = 3, n_jobs=-1)\n",
    "scaler = StandardScaler()\n",
    "clf = ImPineline([\n",
    "#     ('anova', anova_filter),\n",
    "    ('scaler',scaler), \n",
    "    ('smote',smote),\n",
    "    ('model', model)\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if validMode:\n",
    "    rs = clf.fit(x, y)\n",
    "    scores = cross_val_score(clf, x, y, cv=3, n_jobs=-1, verbose=1, scoring='f1_macro')\n",
    "    print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
    "#     preds_test = clf.predict(t_x)\n",
    "    # clf.score(t_x, t_y)\n",
    "#     print(\"%0.3f\" % f1_score(t_y, preds_test, average='macro'))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "[CV] max_leaf_nodes=1200, bootstrap=True, min_samples_leaf=1, n_estimators=100, min_samples_split=2, min_weight_fraction_leaf=0.2, max_features=0.6, max_depth=70 \n",
      "[CV] max_leaf_nodes=1200, bootstrap=True, min_samples_leaf=1, n_estimators=100, min_samples_split=2, min_weight_fraction_leaf=0.2, max_features=0.6, max_depth=70 \n",
      "[CV] max_leaf_nodes=1200, bootstrap=True, min_samples_leaf=1, n_estimators=100, min_samples_split=2, min_weight_fraction_leaf=0.2, max_features=0.6, max_depth=70 \n",
      "[CV] max_leaf_nodes=800, bootstrap=False, min_samples_leaf=20, n_estimators=10, min_samples_split=20, min_weight_fraction_leaf=0.2, max_features=0.5, max_depth=80 \n",
      "[CV] max_leaf_nodes=800, bootstrap=False, min_samples_leaf=20, n_estimators=10, min_samples_split=20, min_weight_fraction_leaf=0.2, max_features=0.5, max_depth=80 \n",
      "[CV] max_leaf_nodes=800, bootstrap=False, min_samples_leaf=20, n_estimators=10, min_samples_split=20, min_weight_fraction_leaf=0.2, max_features=0.5, max_depth=80 \n",
      "[CV] max_leaf_nodes=800, bootstrap=True, min_samples_leaf=4, n_estimators=100, min_samples_split=4, min_weight_fraction_leaf=0.05, max_features=0.7, max_depth=80 \n",
      "[CV] max_leaf_nodes=800, bootstrap=True, min_samples_leaf=4, n_estimators=100, min_samples_split=4, min_weight_fraction_leaf=0.05, max_features=0.7, max_depth=80 \n",
      "[CV]  max_leaf_nodes=800, bootstrap=False, min_samples_leaf=20, n_estimators=10, min_samples_split=20, min_weight_fraction_leaf=0.2, max_features=0.5, max_depth=80 -   9.1s\n",
      "[CV] max_leaf_nodes=800, bootstrap=True, min_samples_leaf=4, n_estimators=100, min_samples_split=4, min_weight_fraction_leaf=0.05, max_features=0.7, max_depth=80 \n",
      "[CV]  max_leaf_nodes=800, bootstrap=False, min_samples_leaf=20, n_estimators=10, min_samples_split=20, min_weight_fraction_leaf=0.2, max_features=0.5, max_depth=80 -   9.7s\n",
      "[CV] max_leaf_nodes=800, bootstrap=False, min_samples_leaf=8, n_estimators=100, min_samples_split=20, min_weight_fraction_leaf=0.1, max_features=0.6, max_depth=80 \n",
      "[CV]  max_leaf_nodes=800, bootstrap=False, min_samples_leaf=20, n_estimators=10, min_samples_split=20, min_weight_fraction_leaf=0.2, max_features=0.5, max_depth=80 -  12.6s\n",
      "[CV] max_leaf_nodes=800, bootstrap=False, min_samples_leaf=8, n_estimators=100, min_samples_split=20, min_weight_fraction_leaf=0.1, max_features=0.6, max_depth=80 \n",
      "[CV]  max_leaf_nodes=1200, bootstrap=True, min_samples_leaf=1, n_estimators=100, min_samples_split=2, min_weight_fraction_leaf=0.2, max_features=0.6, max_depth=70 -  51.0s\n",
      "[CV] max_leaf_nodes=800, bootstrap=False, min_samples_leaf=8, n_estimators=100, min_samples_split=20, min_weight_fraction_leaf=0.1, max_features=0.6, max_depth=80 \n",
      "[CV]  max_leaf_nodes=1200, bootstrap=True, min_samples_leaf=1, n_estimators=100, min_samples_split=2, min_weight_fraction_leaf=0.2, max_features=0.6, max_depth=70 -  52.5s\n",
      "[CV] max_leaf_nodes=1000, bootstrap=False, min_samples_leaf=8, n_estimators=100, min_samples_split=4, min_weight_fraction_leaf=0.1, max_features=0.7, max_depth=20 \n",
      "[CV]  max_leaf_nodes=1200, bootstrap=True, min_samples_leaf=1, n_estimators=100, min_samples_split=2, min_weight_fraction_leaf=0.2, max_features=0.6, max_depth=70 -  59.2s\n",
      "[CV] max_leaf_nodes=1000, bootstrap=False, min_samples_leaf=8, n_estimators=100, min_samples_split=4, min_weight_fraction_leaf=0.1, max_features=0.7, max_depth=20 \n",
      "[CV] max_leaf_nodes=1000, bootstrap=False, min_samples_leaf=8, n_estimators=100, min_samples_split=4, min_weight_fraction_leaf=0.1, max_features=0.7, max_depth=20 \n",
      "[CV] max_leaf_nodes=1000, bootstrap=True, min_samples_leaf=20, n_estimators=100, min_samples_split=2, min_weight_fraction_leaf=0.05, max_features=0.5, max_depth=80 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process PoolWorker-16:\n",
      "Process PoolWorker-14:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/cql/anaconda2/lib/python2.7/multiprocessing/process.py\", line 267, in _bootstrap\n",
      "  File \"/Users/cql/anaconda2/lib/python2.7/multiprocessing/process.py\", line 267, in _bootstrap\n",
      "    self.run()\n",
      "    self.run()\n",
      "  File \"/Users/cql/anaconda2/lib/python2.7/multiprocessing/process.py\", line 114, in run\n",
      "  File \"/Users/cql/anaconda2/lib/python2.7/multiprocessing/process.py\", line 114, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/cql/anaconda2/lib/python2.7/multiprocessing/pool.py\", line 102, in worker\n",
      "  File \"/Users/cql/anaconda2/lib/python2.7/multiprocessing/pool.py\", line 102, in worker\n",
      "    task = get()\n",
      "    task = get()\n",
      "  File \"/Users/cql/anaconda2/lib/python2.7/site-packages/sklearn/externals/joblib/pool.py\", line 362, in get\n",
      "  File \"/Users/cql/anaconda2/lib/python2.7/site-packages/sklearn/externals/joblib/pool.py\", line 360, in get\n",
      "    return recv()\n",
      "    racquire()\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] max_leaf_nodes=1000, bootstrap=True, min_samples_leaf=20, n_estimators=100, min_samples_split=2, min_weight_fraction_leaf=0.05, max_features=0.5, max_depth=80 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process PoolWorker-13:\n",
      "Traceback (most recent call last):\n",
      "Process PoolWorker-18:\n",
      "  File \"/Users/cql/anaconda2/lib/python2.7/multiprocessing/process.py\", line 267, in _bootstrap\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/cql/anaconda2/lib/python2.7/multiprocessing/process.py\", line 267, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/cql/anaconda2/lib/python2.7/multiprocessing/process.py\", line 114, in run\n",
      "    self.run()\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/cql/anaconda2/lib/python2.7/multiprocessing/process.py\", line 114, in run\n",
      "  File \"/Users/cql/anaconda2/lib/python2.7/multiprocessing/pool.py\", line 102, in worker\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "    task = get()\n",
      "  File \"/Users/cql/anaconda2/lib/python2.7/multiprocessing/pool.py\", line 102, in worker\n",
      "  File \"/Users/cql/anaconda2/lib/python2.7/site-packages/sklearn/externals/joblib/pool.py\", line 360, in get\n",
      "    task = get()\n",
      "    racquire()\n",
      "  File \"/Users/cql/anaconda2/lib/python2.7/site-packages/sklearn/externals/joblib/pool.py\", line 362, in get\n",
      "KeyboardInterrupt\n",
      "    return recv()\n",
      "KeyboardInterrupt\n",
      "Process PoolWorker-12:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/cql/anaconda2/lib/python2.7/multiprocessing/process.py\", line 267, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/cql/anaconda2/lib/python2.7/multiprocessing/process.py\", line 114, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/cql/anaconda2/lib/python2.7/multiprocessing/pool.py\", line 113, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] max_leaf_nodes=1000, bootstrap=True, min_samples_leaf=20, n_estimators=100, min_samples_split=2, min_weight_fraction_leaf=0.05, max_features=0.5, max_depth=80 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process PoolWorker-17:\n",
      "Process PoolWorker-20:\n",
      "Traceback (most recent call last):\n",
      "Process PoolWorker-21:\n",
      "  File \"/Users/cql/anaconda2/lib/python2.7/multiprocessing/process.py\", line 267, in _bootstrap\n",
      "Traceback (most recent call last):\n",
      "Exception in thread Thread-18:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/cql/anaconda2/lib/python2.7/threading.py\", line 801, in __bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/Users/cql/anaconda2/lib/python2.7/threading.py\", line 754, in run\n",
      "    self.__target(*self.__args, **self.__kwargs)\n",
      "  File \"/Users/cql/anaconda2/lib/python2.7/multiprocessing/pool.py\", line 328, in _handle_workers\n",
      "    pool._maintain_pool()\n",
      "  File \"/Users/cql/anaconda2/lib/python2.7/multiprocessing/pool.py\", line 232, in _maintain_pool\n",
      "    self._repopulate_pool()\n",
      "  File \"/Users/cql/anaconda2/lib/python2.7/multiprocessing/pool.py\", line 225, in _repopulate_pool\n",
      "    w.start()\n",
      "  File \"/Users/cql/anaconda2/lib/python2.7/multiprocessing/process.py\", line 130, in start\n",
      "    self._popen = Popen(self)\n",
      "  File \"/Users/cql/anaconda2/lib/python2.7/multiprocessing/forking.py\", line 126, in __init__\n",
      "    code = process_obj._bootstrap()\n",
      "  File \"/Users/cql/anaconda2/lib/python2.7/multiprocessing/process.py\", line 285, in _bootstrap\n",
      "    traceback.print_exc()\n",
      "  File \"/Users/cql/anaconda2/lib/python2.7/traceback.py\", line 233, in print_exc\n",
      "    print_exception(etype, value, tb, limit, file)\n",
      "  File \"/Users/cql/anaconda2/lib/python2.7/traceback.py\", line 124, in print_exception\n",
      "    _print(file, 'Traceback (most recent call last):')\n",
      "  File \"/Users/cql/anaconda2/lib/python2.7/traceback.py\", line 13, in _print\n",
      "    file.write(str+terminator)\n",
      "  File \"/Users/cql/anaconda2/lib/python2.7/site-packages/ipykernel/iostream.py\", line 358, in write\n",
      "    self.flush()\n",
      "  File \"/Users/cql/anaconda2/lib/python2.7/site-packages/ipykernel/iostream.py\", line 323, in flush\n",
      "    self._flush()\n",
      "  File \"/Users/cql/anaconda2/lib/python2.7/site-packages/ipykernel/iostream.py\", line 340, in _flush\n",
      "    parent=self.parent_header, ident=self.topic)\n",
      "  File \"/Users/cql/anaconda2/lib/python2.7/site-packages/jupyter_client/session.py\", line 741, in send\n",
      "    stream.send_multipart(to_send, copy=copy)\n",
      "  File \"/Users/cql/anaconda2/lib/python2.7/site-packages/ipykernel/iostream.py\", line 199, in send_multipart\n",
      "    self.schedule(lambda : self._really_send(*args, **kwargs))\n",
      "  File \"/Users/cql/anaconda2/lib/python2.7/site-packages/ipykernel/iostream.py\", line 192, in schedule\n",
      "    f()\n",
      "  File \"/Users/cql/anaconda2/lib/python2.7/site-packages/ipykernel/iostream.py\", line 199, in <lambda>\n",
      "    self.schedule(lambda : self._really_send(*args, **kwargs))\n",
      "  File \"/Users/cql/anaconda2/lib/python2.7/site-packages/ipykernel/iostream.py\", line 215, in _really_send\n",
      "    ctx.term()\n",
      "  File \"zmq/backend/cython/context.pyx\", line 136, in zmq.backend.cython.context.Context.term (zmq/backend/cython/context.c:2339)\n",
      "  File \"zmq/backend/cython/checkrc.pxd\", line 12, in zmq.backend.cython.checkrc._check_rc (zmq/backend/cython/context.c:3207)\n",
      "    PyErr_CheckSignals()\n",
      "KeyboardInterrupt\n",
      "Exception in thread Thread-18:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/cql/anaconda2/lib/python2.7/threading.py\", line 801, in __bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/Users/cql/anaconda2/lib/python2.7/threading.py\", line 754, in run\n",
      "    self.__target(*self.__args, **self.__kwargs)\n",
      "  File \"/Users/cql/anaconda2/lib/python2.7/multiprocessing/pool.py\", line 328, in _handle_workers\n",
      "    pool._maintain_pool()\n",
      "  File \"/Users/cql/anaconda2/lib/python2.7/multiprocessing/pool.py\", line 232, in _maintain_pool\n",
      "    self._repopulate_pool()\n",
      "  File \"/Users/cql/anaconda2/lib/python2.7/multiprocessing/pool.py\", line 225, in _repopulate_pool\n",
      "    w.start()\n",
      "  File \"/Users/cql/anaconda2/lib/python2.7/multiprocessing/process.py\", line 130, in start\n",
      "    self._popen = Popen(self)\n",
      "  File \"/Users/cql/anaconda2/lib/python2.7/multiprocessing/forking.py\", line 126, in __init__\n",
      "    code = process_obj._bootstrap()\n",
      "  File \"/Users/cql/anaconda2/lib/python2.7/multiprocessing/process.py\", line 285, in _bootstrap\n",
      "    traceback.print_exc()\n",
      "  File \"/Users/cql/anaconda2/lib/python2.7/traceback.py\", line 233, in print_exc\n",
      "    print_exception(etype, value, tb, limit, file)\n",
      "  File \"/Users/cql/anaconda2/lib/python2.7/traceback.py\", line 124, in print_exception\n",
      "    _print(file, 'Traceback (most recent call last):')\n",
      "  File \"/Users/cql/anaconda2/lib/python2.7/traceback.py\", line 13, in _print\n",
      "    file.write(str+terminator)\n",
      "  File \"/Users/cql/anaconda2/lib/python2.7/site-packages/ipykernel/iostream.py\", line 358, in write\n",
      "    self.flush()\n",
      "  File \"/Users/cql/anaconda2/lib/python2.7/site-packages/ipykernel/iostream.py\", line 323, in flush\n",
      "    self._flush()\n",
      "  File \"/Users/cql/anaconda2/lib/python2.7/site-packages/ipykernel/iostream.py\", line 340, in _flush\n",
      "    parent=self.parent_header, ident=self.topic)\n",
      "  File \"/Users/cql/anaconda2/lib/python2.7/site-packages/jupyter_client/session.py\", line 741, in send\n",
      "    stream.send_multipart(to_send, copy=copy)\n",
      "  File \"/Users/cql/anaconda2/lib/python2.7/site-packages/ipykernel/iostream.py\", line 199, in send_multipart\n",
      "    self.schedule(lambda : self._really_send(*args, **kwargs))\n",
      "  File \"/Users/cql/anaconda2/lib/python2.7/site-packages/ipykernel/iostream.py\", line 192, in schedule\n",
      "    f()\n",
      "  File \"/Users/cql/anaconda2/lib/python2.7/site-packages/ipykernel/iostream.py\", line 199, in <lambda>\n",
      "    self.schedule(lambda : self._really_send(*args, **kwargs))\n",
      "  File \"/Users/cql/anaconda2/lib/python2.7/site-packages/ipykernel/iostream.py\", line 212, in _really_send\n",
      "    ctx, pipe_out = self._setup_pipe_out()\n",
      "  File \"/Users/cql/anaconda2/lib/python2.7/site-packages/ipykernel/iostream.py\", line 142, in _setup_pipe_out\n",
      "    pipe_out.linger = 3000 # 3s timeout for pipe_out sends before discarding the message\n",
      "  File \"/Users/cql/anaconda2/lib/python2.7/site-packages/zmq/sugar/socket.py\", line 150, in __setattr__\n",
      "    super(Socket, self).__setattr__(key, value)\n",
      "  File \"/Users/cql/anaconda2/lib/python2.7/site-packages/zmq/sugar/attrsettr.py\", line 29, in __setattr__\n",
      "    self._set_attr_opt(upper_key, opt, value)\n",
      "KeyboardInterrupt\n",
      "\n",
      "\n",
      "Exception in thread Thread-18:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/cql/anaconda2/lib/python2.7/threading.py\", line 801, in __bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/Users/cql/anaconda2/lib/python2.7/threading.py\", line 754, in run\n",
      "    self.__target(*self.__args, **self.__kwargs)\n",
      "  File \"/Users/cql/anaconda2/lib/python2.7/multiprocessing/pool.py\", line 328, in _handle_workers\n",
      "    pool._maintain_pool()\n",
      "  File \"/Users/cql/anaconda2/lib/python2.7/multiprocessing/pool.py\", line 232, in _maintain_pool\n",
      "    self._repopulate_pool()\n",
      "  File \"/Users/cql/anaconda2/lib/python2.7/multiprocessing/pool.py\", line 225, in _repopulate_pool\n",
      "    w.start()\n",
      "  File \"/Users/cql/anaconda2/lib/python2.7/multiprocessing/process.py\", line 130, in start\n",
      "    self._popen = Popen(self)\n",
      "  File \"/Users/cql/anaconda2/lib/python2.7/multiprocessing/forking.py\", line 126, in __init__\n",
      "    code = process_obj._bootstrap()\n",
      "  File \"/Users/cql/anaconda2/lib/python2.7/multiprocessing/process.py\", line 285, in _bootstrap\n",
      "    traceback.print_exc()\n",
      "  File \"/Users/cql/anaconda2/lib/python2.7/traceback.py\", line 233, in print_exc\n",
      "    print_exception(etype, value, tb, limit, file)\n",
      "  File \"/Users/cql/anaconda2/lib/python2.7/traceback.py\", line 125, in print_exception\n",
      "    print_tb(tb, limit, file)\n",
      "  File \"/Users/cql/anaconda2/lib/python2.7/traceback.py\", line 67, in print_tb\n",
      "    '  File \"%s\", line %d, in %s' % (filename, lineno, name))\n",
      "  File \"/Users/cql/anaconda2/lib/python2.7/traceback.py\", line 13, in _print\n",
      "    file.write(str+terminator)\n",
      "  File \"/Users/cql/anaconda2/lib/python2.7/site-packages/ipykernel/iostream.py\", line 358, in write\n",
      "    self.flush()\n",
      "  File \"/Users/cql/anaconda2/lib/python2.7/site-packages/ipykernel/iostream.py\", line 323, in flush\n",
      "    self._flush()\n",
      "  File \"/Users/cql/anaconda2/lib/python2.7/site-packages/ipykernel/iostream.py\", line 340, in _flush\n",
      "    parent=self.parent_header, ident=self.topic)\n",
      "  File \"/Users/cql/anaconda2/lib/python2.7/site-packages/jupyter_client/session.py\", line 741, in send\n",
      "    stream.send_multipart(to_send, copy=copy)\n",
      "  File \"/Users/cql/anaconda2/lib/python2.7/site-packages/ipykernel/iostream.py\", line 199, in send_multipart\n",
      "    self.schedule(lambda : self._really_send(*args, **kwargs))\n",
      "  File \"/Users/cql/anaconda2/lib/python2.7/site-packages/ipykernel/iostream.py\", line 192, in schedule\n",
      "    f()\n",
      "  File \"/Users/cql/anaconda2/lib/python2.7/site-packages/ipykernel/iostream.py\", line 199, in <lambda>\n",
      "    self.schedule(lambda : self._really_send(*args, **kwargs))\n",
      "  File \"/Users/cql/anaconda2/lib/python2.7/site-packages/ipykernel/iostream.py\", line 215, in _really_send\n",
      "    ctx.term()\n",
      "  File \"zmq/backend/cython/context.pyx\", line 136, in zmq.backend.cython.context.Context.term (zmq/backend/cython/context.c:2339)\n",
      "  File \"zmq/backend/cython/checkrc.pxd\", line 12, in zmq.backend.cython.checkrc._check_rc (zmq/backend/cython/context.c:3207)\n",
      "    PyErr_CheckSignals()\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-63-dc00bad8ee2a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m     clf = RandomizedSearchCV(RandomForestClassifier(n_jobs=8, class_weight='balanced'), parameters, cv=3,\n\u001b[1;32m     17\u001b[0m                            scoring='f1_macro', n_jobs=8, verbose=2)\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m     \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mmeans\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcv_results_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'mean_test_score'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/cql/anaconda2/lib/python2.7/site-packages/sklearn/grid_search.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m   1044\u001b[0m                                           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_iter\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1045\u001b[0m                                           random_state=self.random_state)\n\u001b[0;32m-> 1046\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msampled_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/cql/anaconda2/lib/python2.7/site-packages/sklearn/grid_search.pyc\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, parameter_iterable)\u001b[0m\n\u001b[1;32m    572\u001b[0m                                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_parameters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    573\u001b[0m                                     error_score=self.error_score)\n\u001b[0;32m--> 574\u001b[0;31m                 \u001b[0;32mfor\u001b[0m \u001b[0mparameters\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparameter_iterable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    575\u001b[0m                 for train, test in cv)\n\u001b[1;32m    576\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/cql/anaconda2/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    787\u001b[0m                 \u001b[0;31m# consumption.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 789\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    790\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/cql/anaconda2/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    719\u001b[0m                     \u001b[0;31m# scheduling.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    720\u001b[0m                     \u001b[0mensure_ready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_managed_backend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 721\u001b[0;31m                     \u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabort_everything\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mensure_ready\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mensure_ready\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    722\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    723\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexception\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTransportableException\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/cql/anaconda2/lib/python2.7/site-packages/sklearn/externals/joblib/_parallel_backends.pyc\u001b[0m in \u001b[0;36mabort_everything\u001b[0;34m(self, ensure_ready)\u001b[0m\n\u001b[1;32m    143\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mabort_everything\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_ready\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m         \u001b[0;34m\"\"\"Shutdown the pool and restart a new one with the same parameters\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 145\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mterminate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    146\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mensure_ready\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m             self.configure(n_jobs=self.parallel.n_jobs, parallel=self.parallel,\n",
      "\u001b[0;32m/Users/cql/anaconda2/lib/python2.7/site-packages/sklearn/externals/joblib/_parallel_backends.pyc\u001b[0m in \u001b[0;36mterminate\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    321\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mterminate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m         \u001b[0;34m\"\"\"Shutdown the process or thread pool\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 323\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMultiprocessingBackend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mterminate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    324\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mJOBLIB_SPAWNED_PROCESS\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mJOBLIB_SPAWNED_PROCESS\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/cql/anaconda2/lib/python2.7/site-packages/sklearn/externals/joblib/_parallel_backends.pyc\u001b[0m in \u001b[0;36mterminate\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    134\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pool\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 136\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mterminate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# terminate does a join()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    137\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/cql/anaconda2/lib/python2.7/site-packages/sklearn/externals/joblib/pool.pyc\u001b[0m in \u001b[0;36mterminate\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    604\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_retries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    605\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 606\u001b[0;31m                 \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMemmapingPool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mterminate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    607\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    608\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/cql/anaconda2/lib/python2.7/multiprocessing/pool.pyc\u001b[0m in \u001b[0;36mterminate\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    468\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTERMINATE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    469\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_worker_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTERMINATE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 470\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_terminate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    471\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    472\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/cql/anaconda2/lib/python2.7/multiprocessing/util.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, wr)\u001b[0m\n\u001b[1;32m    205\u001b[0m                 sub_debug('finalizer calling %s with args %s and kwargs %s',\n\u001b[1;32m    206\u001b[0m                           self._callback, self._args, self._kwargs)\n\u001b[0;32m--> 207\u001b[0;31m                 \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    208\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_weakref\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callback\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_args\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m                             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_kwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_key\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/cql/anaconda2/lib/python2.7/multiprocessing/pool.pyc\u001b[0m in \u001b[0;36m_terminate_pool\u001b[0;34m(cls, taskqueue, inqueue, outqueue, pool, worker_handler, task_handler, result_handler, cache)\u001b[0m\n\u001b[1;32m    532\u001b[0m                     \u001b[0;31m# worker has not yet exited\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    533\u001b[0m                     \u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cleaning up worker %d'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 534\u001b[0;31m                     \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    535\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    536\u001b[0m \u001b[0;31m#\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/cql/anaconda2/lib/python2.7/multiprocessing/process.pyc\u001b[0m in \u001b[0;36mjoin\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    146\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_pid\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetpid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'can only join a child process'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_popen\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'can only join a started process'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 148\u001b[0;31m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_popen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    149\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m             \u001b[0m_current_process\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_children\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiscard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/cql/anaconda2/lib/python2.7/multiprocessing/forking.pyc\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    152\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 154\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    155\u001b[0m             \u001b[0mdeadline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m             \u001b[0mdelay\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0005\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/cql/anaconda2/lib/python2.7/multiprocessing/forking.pyc\u001b[0m in \u001b[0;36mpoll\u001b[0;34m(self, flag)\u001b[0m\n\u001b[1;32m    133\u001b[0m                 \u001b[0;32mwhile\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m                     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 135\u001b[0;31m                         \u001b[0mpid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwaitpid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflag\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    136\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrno\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0merrno\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEINTR\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if validMode:\n",
    "    smote = SMOTE()\n",
    "    parameters = {\n",
    "        'max_depth':[20, 60, 70, 80],  #70\n",
    "        'max_features':[0.5,0.6,0.7], #0.6\n",
    "        'min_samples_split':[2, 4, 8, 20], #2\n",
    "        'min_samples_leaf':[1,4,8,20], #1\n",
    "        'min_weight_fraction_leaf':[0,0.05,0.1,0.2], #0\n",
    "        'max_leaf_nodes':[800, 1000, 1200], #1000\n",
    "         'bootstrap':[True, False], #False\n",
    "    #     'oob_score':[True, False], #False\n",
    "    #     'class_weight':[None,'balanced'], #balanced\n",
    "        'n_estimators':[10, 20, 100], #10\n",
    "    #     'criterion':['gini','entropy']\n",
    "    }\n",
    "    clf = RandomizedSearchCV(RandomForestClassifier(n_jobs=8, class_weight='balanced'), parameters, cv=3,\n",
    "                           scoring='f1_macro', n_jobs=8, verbose=2)\n",
    "    clf.fit(x, y)\n",
    "    print(clf.best_params_)\n",
    "    means = clf.cv_results_['mean_test_score']\n",
    "    stds = clf.cv_results_['std_test_score']\n",
    "    for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "        print(\"%0.3f (+/-%0.03f) for %r\" % (mean, std * 2, params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if validMode:\n",
    "    rs = clf.fit(x, y)\n",
    "    preds_test = clf.predict(t_x)\n",
    "#     preds_test = carbateQso(t_x, preds_test)\n",
    "#     clf.score(t_x, t_y)\n",
    "    print(\"%0.3f\" % f1_score(t_y, preds_test, average='macro'))  \n",
    "    print(classification_report(t_y, preds_test, labels=['galaxy', 'qso', 'star', 'unknown']))\n",
    "    print(confusion_matrix(t_y, preds_test, labels=['galaxy', 'qso', 'star', 'unknown']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def carbateQso(t_x, preds_test):\n",
    "    fPreds = pd.concat([t_x.reset_index(), pd.DataFrame(preds_test)], axis=1)\n",
    "    fPreds[(fPreds.iloc[:,-1]=='unknown')&(fPreds.qso_f3>2)].iloc[:,-1] = 'qso'\n",
    "    return fPreds.iloc[:,-1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if validMode:\n",
    "    clf = RandomForestClassifier(n_jobs=-1, class_weight='balanced',  verbose=1 )\n",
    "    rs = clf.fit(x, y)\n",
    "    preds_test = clf.predict(t_x)\n",
    "    # clf.score(t_x, t_y)\n",
    "    print('f1: %.2f' % f1_score(t_y, preds_test, average='macro')) \n",
    "    print(classification_report(t_y, preds_test, labels=['galaxy', 'qso', 'star', 'unknown']))\n",
    "    print(confusion_matrix(t_y, preds_test, labels=['galaxy', 'qso', 'star', 'unknown']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if validMode:\n",
    "    importances = model.feature_importances_\n",
    "    std = np.std([tree.feature_importances_ for tree in model.estimators_],\n",
    "                 axis=0)\n",
    "    indices = np.argsort(importances)[::-1]\n",
    "\n",
    "    # Print the feature ranking\n",
    "    print(\"Feature ranking:\")\n",
    "\n",
    "    for f in range(X.shape[1]):\n",
    "        print(\"%d. feature %d (%f)\" % (f + 1, indices[f], importances[indices[f]]))\n",
    "\n",
    "    # Plot the feature importances of the forest\n",
    "    plt.figure()\n",
    "    plt.title(\"Feature importances\")\n",
    "    plt.bar(range(X.shape[1]), importances[indices],\n",
    "           color=\"r\", yerr=std[indices], align=\"center\")\n",
    "    plt.xticks(range(X.shape[1]), indices)\n",
    "    plt.xlim([-1, X.shape[1]])\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing:0\n",
      "processing:1\n",
      "processing:2\n",
      "processing:3\n",
      "processing:4\n",
      "processing:5\n",
      "processing:6\n",
      "processing:7\n",
      "processing:8\n",
      "processing:9\n"
     ]
    }
   ],
   "source": [
    "if reFeature:\n",
    "    testTotal = readTotalFeature('./test_feature_all_', 9, hasLabel=False, partition=partition)\n",
    "    testTotal.to_csv('./test_feature_checkpoint.csv', index=False)\n",
    "    testTotal.head()\n",
    "else :\n",
    "    testTotal = pd.read_csv('./test_feature_checkpoint.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100000, 334)"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testTotal.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(483851, 333)"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Done   6 out of  10 | elapsed:  1.6min remaining:  1.1min\n",
      "[Parallel(n_jobs=8)]: Done  10 out of  10 | elapsed:  2.7min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('scaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('smote', SMOTE(k=None, k_neighbors=5, kind='regular', m=None, m_neighbors=10, n_jobs=1,\n",
       "   out_step=0.5, random_state=None, ratio='auto', svm_estimator=None)), ('model', RandomForestClassifier(bootstrap=True, class_weight=...random_state=<mtrand.RandomState object at 0x1c1288caf0>,\n",
       "            verbose=1, warm_start=False))])"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X, Y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Done   6 out of  10 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done  10 out of  10 | elapsed:    0.1s finished\n",
      "/Users/cql/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "test_x = testTotal.iloc[:,:-1]\n",
    "pred = clf.predict(test_x)\n",
    "timestr = time.strftime(\"%m%d_%H%M\")\n",
    "rs = submit(timestr+'_rf_ew_more_erange.csv',testTotal, pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "star       85831\n",
       "unknown    10545\n",
       "galaxy      2383\n",
       "qso         1241\n",
       "Name: pred, dtype: int64"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rs.pred.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_train_feature.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_train_feature[:,:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
